{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ccaa25-bad4-45de-bacf-431cb9b56543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State of the Union Address addressing freedom-related topics: Document 225\n",
      "State of the Union Address addressing security-related topics: Document 216\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "documents = []\n",
    "with open(\"UnionAddressTable_All.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        documents.append(row[4])\n",
    "\n",
    "# Define user query topics\n",
    "query_topics_1 = [\"freedom\", \"freedom of speech\", \"freedom of press\"]\n",
    "query_topics_2 = [\"security\", \"peace\", \"reestablishment of peace\", \"preservation of peace\"]\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove special characters and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    stemmer = PorterStemmer()\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def count_term_frequency(documents):\n",
    "    term_frequency = []\n",
    "    for document in documents:\n",
    "        words = tokenize(document)\n",
    "        term_frequency.append(Counter(words))\n",
    "    return term_frequency\n",
    "\n",
    "def calculate_df(documents, topics):\n",
    "    df = Counter()\n",
    "    for document in documents:\n",
    "        words = set(tokenize(document))\n",
    "        for topic in topics:\n",
    "            if topic in words:\n",
    "                df[topic] += 1\n",
    "    return df\n",
    "\n",
    "def calculate_tfidf(tf, df, num_documents):\n",
    "    tfidf = {}\n",
    "    for term, tf_value in tf.items():\n",
    "        if df[term] != 0:\n",
    "            idf = math.log(num_documents / df[term])\n",
    "            tfidf[term] = tf_value * idf\n",
    "        else:\n",
    "            tfidf[term] = 0\n",
    "    return tfidf\n",
    "\n",
    "def construct_document_vectors(documents, topics):\n",
    "    num_documents = len(documents)\n",
    "    document_vectors = []\n",
    "    term_frequency = count_term_frequency(documents)\n",
    "    df = calculate_df(documents, topics)\n",
    "    for tf in term_frequency:\n",
    "        tfidf = calculate_tfidf(tf, df, num_documents)\n",
    "        document_vectors.append(tfidf)\n",
    "    return document_vectors\n",
    "\n",
    "def calculate_similarity(document_vector, query_topics):\n",
    "    similarity = sum(document_vector.get(topic, 0) for topic in query_topics)\n",
    "    return similarity\n",
    "\n",
    "def find_best_match(documents, query_topics):\n",
    "    document_vectors = construct_document_vectors(documents, query_topics)\n",
    "    best_match = None\n",
    "    best_similarity = -1\n",
    "    for i, document_vector in enumerate(document_vectors):\n",
    "        similarity = calculate_similarity(document_vector, query_topics)\n",
    "        if similarity > best_similarity:\n",
    "            best_similarity = similarity\n",
    "            best_match = i\n",
    "    return best_match\n",
    "\n",
    "best_match_1 = find_best_match(documents, query_topics_1)\n",
    "print(\"State of the Union Address addressing freedom-related topics: Document\", best_match_1+1)\n",
    "\n",
    "best_match_2 = find_best_match(documents, query_topics_2)\n",
    "print(\"State of the Union Address addressing security-related topics: Document\", best_match_2+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
